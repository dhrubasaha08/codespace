{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d82c6a8",
   "metadata": {
    "id": "2d82c6a8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DGLBACKEND'] = 'pytorch'\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import dgl.function as fn\n",
    "import dgl\n",
    "from dgllife.data import Tox21\n",
    "from dgllife.utils import SMILESToBigraph, CanonicalAtomFeaturizer, CanonicalBondFeaturizer, RandomSplitter\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from dgl.data.utils import split_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score as rac\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm,trange\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6347fd83",
   "metadata": {
    "id": "6347fd83"
   },
   "outputs": [],
   "source": [
    "smiles_to_g = SMILESToBigraph(node_featurizer=CanonicalAtomFeaturizer(), edge_featurizer=CanonicalBondFeaturizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86048dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b86048dd",
    "outputId": "518035a8-2f73-4fee-82b0-e2ee297526f8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading C:\\Users\\dhrub\\.dgl/tox21.csv.gz from https://data.dgl.ai/dataset/tox21.csv.gz...\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/7831\n",
      "Processing molecule 2000/7831\n",
      "Processing molecule 3000/7831\n",
      "Processing molecule 4000/7831\n",
      "Processing molecule 5000/7831\n",
      "Processing molecule 6000/7831\n",
      "Processing molecule 7000/7831\n"
     ]
    }
   ],
   "source": [
    "dataset = Tox21(smiles_to_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb2286d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cb2286d8",
    "outputId": "f6277398-63f1-43ec-a928-3cc2adcb9bc2",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CCOc1ccc2nc(S(N)(=O)=O)sc2c1',\n",
       " Graph(num_nodes=16, num_edges=34,\n",
       "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
       "       edata_schemes={'e': Scheme(shape=(12,), dtype=torch.float32)}),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "034ed86c",
   "metadata": {
    "id": "034ed86c"
   },
   "outputs": [],
   "source": [
    "#Batching a list of datapoints for dataloader.\n",
    "def collate_molgraphs(data):\n",
    "    smiles, graphs, labels, masks = map(list, zip(*data))\n",
    "\n",
    "    g = dgl.batch(graphs)\n",
    "    g.set_n_initializer(dgl.init.zero_initializer)\n",
    "    g.set_e_initializer(dgl.init.zero_initializer)\n",
    "    labels = torch.stack(labels, dim=0)\n",
    "    masks = torch.stack(masks, dim=0)\n",
    "    return smiles, g, labels, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f38763f0",
   "metadata": {
    "id": "f38763f0"
   },
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = split_dataset(dataset, shuffle=True)\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, collate_fn=collate_molgraphs)\n",
    "val_loader = DataLoader(val_set, batch_size=128, shuffle=True, collate_fn=collate_molgraphs)\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=True, collate_fn=collate_molgraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "827ba60e",
   "metadata": {
    "id": "827ba60e"
   },
   "outputs": [],
   "source": [
    "class Meter(object):\n",
    "    \"\"\"Track and summarize model performance on a dataset for\n",
    "    (multi-label) binary classification.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.mask = []\n",
    "        self.y_pred = []\n",
    "        self.y_true = []\n",
    "\n",
    "    def update(self, y_pred, y_true, mask):\n",
    "        \"\"\"Update for the result of an iteration\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : float32 tensor\n",
    "            Predicted molecule labels with shape (B, T),\n",
    "            B for batch size and T for the number of tasks\n",
    "        y_true : float32 tensor\n",
    "            Ground truth molecule labels with shape (B, T)\n",
    "        mask : float32 tensor\n",
    "            Mask for indicating the existence of ground\n",
    "            truth labels with shape (B, T)\n",
    "        \"\"\"\n",
    "        self.y_pred.append(y_pred.detach().cpu())\n",
    "        self.y_true.append(y_true.detach().cpu())\n",
    "        self.mask.append(mask.detach().cpu())\n",
    "\n",
    "    def roc_auc_score(self):\n",
    "        \"\"\"Compute roc-auc score for each task.\n",
    "        Returns\n",
    "        -------\n",
    "        list of float\n",
    "            roc-auc score for all tasks\n",
    "        \"\"\"\n",
    "        mask = torch.cat(self.mask, dim=0)\n",
    "        y_pred = torch.cat(self.y_pred, dim=0)\n",
    "        y_true = torch.cat(self.y_true, dim=0)\n",
    "        # This assumes binary case only\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        n_tasks = y_true.shape[1]\n",
    "        scores = []\n",
    "        for task in range(n_tasks):\n",
    "            task_w = mask[:, task]\n",
    "            task_y_true = y_true[:, task][task_w != 0].numpy()\n",
    "            task_y_pred = y_pred[:, task][task_w != 0].numpy()\n",
    "            scores.append(rac(task_y_true, task_y_pred))\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53908ab2",
   "metadata": {
    "id": "53908ab2"
   },
   "outputs": [],
   "source": [
    "def run_an_eval_epoch(model, data_loader):\n",
    "    model.eval()\n",
    "    eval_meter = Meter()\n",
    "    with torch.no_grad():\n",
    "        for batch_id, batch_data in enumerate(data_loader):\n",
    "            smiles, g, labels, masks = batch_data\n",
    "            atom_feats = g.ndata.pop('h')\n",
    "            bond_feats = g.edata.pop('e')\n",
    "            atom_feats, bond_feats, labels = atom_feats, bond_feats, labels\n",
    "            logits = model(g, atom_feats, bond_feats)\n",
    "            eval_meter.update(logits, labels, masks)\n",
    "    return np.mean(eval_meter.roc_auc_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9aa7f8c",
   "metadata": {
    "id": "d9aa7f8c"
   },
   "outputs": [],
   "source": [
    "train_ids = torch.arange(1000)\n",
    "def run_a_train_epoch(train_loader, val_loader, model):\n",
    "    loss_criterion = BCEWithLogitsLoss(pos_weight=torch.tensor(dataset.task_pos_weights(train_ids)), reduction=\"none\")\n",
    "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "    \n",
    "    for epoch in trange(2):\n",
    "        model.train()\n",
    "        train_meter = Meter()\n",
    "        total_loss = 0\n",
    "        for batch_id, batch_data in enumerate(train_loader):\n",
    "            smiles, g, labels, masks = batch_data\n",
    "            atom_feats = g.ndata.pop('h')\n",
    "            bond_feats = g.edata.pop('e')\n",
    "            logits = model(g, atom_feats, bond_feats)\n",
    "            # Mask non-existing labels\n",
    "            loss = (loss_criterion(logits, labels) * (masks != 0).float()).mean()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        train_acc = run_an_eval_epoch(model, train_loader)\n",
    "        valid_acc = run_an_eval_epoch(model, val_loader)\n",
    "        print(\n",
    "            \"Epoch {:05d} | Loss {:.4f} | Train Acc. {:.4f} | Validation Acc. {:.4f} \".format(\n",
    "                epoch, total_loss / 10, train_acc, valid_acc\n",
    "            )\n",
    "        )\n",
    "        train_meter.update(logits, labels, masks)\n",
    "    train_score = np.mean(train_meter.roc_auc_score())\n",
    "    print(\n",
    "        \"epoch {:d}/{:d}, training roc-auc {:.4f}\".format(epoch + 1, 10 , train_score)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "513c2bf2",
   "metadata": {
    "id": "513c2bf2"
   },
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, e_feat):\n",
    "        super(GATLayer, self).__init__()\n",
    "        #self.g = g\n",
    "        # equation (1)\n",
    "        self.fc = nn.Linear(in_feat, out_feat, bias=False)\n",
    "        # equation (2)\n",
    "        self.attn_fc = nn.Linear(2 * out_feat, 1, bias=False)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reinitialize learnable parameters.\"\"\"\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.fc.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_fc.weight, gain=gain)\n",
    "\n",
    "    def edge_attention(self, edges):\n",
    "        # edge UDF for equation (2)\n",
    "        z2 = torch.cat([edges.src['z'], edges.dst['z']], dim=1)\n",
    "        a = self.attn_fc(z2)\n",
    "        return {'e': F.leaky_relu(a)}\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        # message UDF for equation (3) & (4)\n",
    "        return {'z': edges.src['z'], 'e': edges.data['e']}\n",
    "\n",
    "    def reduce_func(self, nodes):\n",
    "        # reduce UDF for equation (3) & (4)\n",
    "        # equation (3)\n",
    "        alpha = F.softmax(nodes.mailbox['e'], dim=1)\n",
    "        # equation (4)\n",
    "        h = torch.sum(alpha * nodes.mailbox['z'], dim=1)\n",
    "        return {'h': h}\n",
    "\n",
    "    def forward(self, g, h, e):\n",
    "        # equation (1)\n",
    "        #self.g = g\n",
    "        z = self.fc(h)\n",
    "        self.g.ndata['z'] = z\n",
    "        # equation (2)\n",
    "        self.g.apply_edges(self.edge_attention)\n",
    "        # equation (3) & (4)\n",
    "        self.g.update_all(self.message_func, self.reduce_func)\n",
    "        return self.g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63f4f7d9",
   "metadata": {
    "id": "63f4f7d9"
   },
   "outputs": [],
   "source": [
    "class GATLayer1(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, e_feat):\n",
    "        super(GATLayer1, self).__init__()\n",
    "        #self.g = g\n",
    "        # equation (1)\n",
    "        self.fc = nn.Linear(in_feat+out_feat, out_feat, bias=False)\n",
    "        self.fc1 = nn.Linear(e_feat, out_feat, bias = False)\n",
    "        self.fc2 = nn.Linear(in_feat, out_feat, bias=False)\n",
    "        # equation (2)\n",
    "        self.attn_fc = nn.Linear(2 * out_feat, 1, bias=False)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reinitialize learnable parameters.\"\"\"\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.fc.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_fc.weight, gain=gain)\n",
    "\n",
    "    def edge_attention(self, edges):\n",
    "        # edge UDF for equation (2)\n",
    "        z2 = torch.cat([edges.src['z'], edges.dst['z']], dim=1)\n",
    "        a = self.attn_fc(z2)\n",
    "        return {'e': F.leaky_relu(a)}\n",
    "    \n",
    "    def edge_attention1(self, edges):\n",
    "    \n",
    "        # edge UDF for equation (2)\n",
    "        catfeat = torch.cat([edges.src['z'], edges.dst['z']], dim=1)\n",
    "        node_embedding=[]\n",
    "        for i in range(0, len(catfeat)):\n",
    "            u = edges.data['y'][i]\n",
    "            v = catfeat[i]\n",
    "            res = torch.from_numpy(signal.fftconvolve((v.detach().numpy()), (u.detach().numpy()), mode='same'))\n",
    "            node_embedding.append(res)\n",
    "        probs = torch.stack([node_embedding[i].clone().detach().requires_grad_(True) for i in range(0,len(node_embedding))])\n",
    "        a = self.attn_fc(probs)\n",
    "        return {'f': F.leaky_relu(a)}\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        # message UDF for equation (3) & (4)\n",
    "        return {'z': edges.src['z'], 'f': edges.data['f']}\n",
    "\n",
    "    def reduce_func(self, nodes):\n",
    "        # reduce UDF for equation (3) & (4)\n",
    "        # equation (3)\n",
    "        alpha = F.softmax(nodes.mailbox['f'], dim=1)\n",
    "        #alpha = nodes.mailbox['f']\n",
    "        # equation (4)\n",
    "        k = torch.sum(alpha * nodes.mailbox['z'], dim=1)\n",
    "        return {'k': k}\n",
    "\n",
    "    def forward(self, g, h, e):\n",
    "        # equation (1)\n",
    "        #self.g = g\n",
    "        with g.local_scope():\n",
    "            g.ndata[\"h\"] = h\n",
    "            g.edata[\"e\"] = e\n",
    "            #print(h.size())\n",
    "            z = self.fc2(h)\n",
    "            y = self.fc1(e)\n",
    "            #print(z.size())\n",
    "\n",
    "            g.ndata['z'] = z\n",
    "            g.edata['y'] = y\n",
    "        # equation (2)\n",
    "            g.apply_edges(self.edge_attention1)\n",
    "        # equation (3) & (4)\n",
    "            g.update_all(self.message_func, self.reduce_func)\n",
    "            h_N = g.ndata[\"k\"]\n",
    "            #print(h_N.size())\n",
    "            #print(h.size())\n",
    "            h_total = torch.cat([h, h_N], dim=1)\n",
    "            h_new = self.fc(h_total)\n",
    "            return [h_new, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ef9d1c4",
   "metadata": {
    "id": "9ef9d1c4"
   },
   "outputs": [],
   "source": [
    "class MultiHeadGATLayer(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, e_feats, num_classes, num_heads, merge='cat'):\n",
    "        super(MultiHeadGATLayer, self).__init__()\n",
    "        self.heads = nn.ModuleList()\n",
    "        for i in range(num_heads):\n",
    "            self.heads.append(GATLayer1(in_feats, h_feats, e_feats))\n",
    "        self.merge = merge\n",
    "\n",
    "    def forward(self, g, in_feat, e_feat):\n",
    "        head_outs_node = [attn_head(g, in_feat, e_feat)[0] for attn_head in self.heads]\n",
    "        head_outs_edge = [attn_head(g, in_feat, e_feat)[1] for attn_head in self.heads]\n",
    "        if self.merge == 'cat':\n",
    "            # concat on the output feature dimension (dim=1)\n",
    "            #print(type(head_outs_node))\n",
    "            #print(type(head_outs_edge))\n",
    "            return torch.cat(head_outs_node, dim=1), torch.cat(head_outs_edge, dim=1)\n",
    "        else:\n",
    "            # merge using average\n",
    "            return torch.mean(torch.stack(head_outs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ec20a29",
   "metadata": {
    "id": "3ec20a29"
   },
   "source": [
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, e_feats, num_classes):\n",
    "        super(GAT, self).__init__()\n",
    "        self.layer1 = GATLayer1(in_feats, h_feats, e_feats)\n",
    "        # Be aware that the input dimension is hidden_dim*num_heads since\n",
    "        # multiple head outputs are concatenated together. Also, only\n",
    "        # one attention head in the output layer.\n",
    "        self.layer2 = GATLayer1(h_feats, num_classes, e_feats)\n",
    "\n",
    "    def forward(self, g, in_feat, e_feat):\n",
    "        h = self.layer1(g, in_feat, e_feat)\n",
    "        #print(h.size())\n",
    "        h = F.elu(h)\n",
    "        h = self.layer2(g, h, e_feat)\n",
    "        g.ndata[\"h\"] = h\n",
    "        return dgl.max_nodes(g, \"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4caa3493",
   "metadata": {
    "id": "4caa3493"
   },
   "outputs": [],
   "source": [
    "class GAT1(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, e_feats, num_classes, num_heads):\n",
    "        super(GAT1, self).__init__()\n",
    "        self.layer1 = MultiHeadGATLayer(in_feats, h_feats, e_feats,__, num_heads)\n",
    "        # Be aware that the input dimension is hidden_dim*num_heads since\n",
    "        # multiple head outputs are concatenated together. Also, only\n",
    "        # one attention head in the output layer.\n",
    "        #self.layer2 = MultiHeadGATLayer(h_feats*num_heads, num_classes, e_feats,__,1)\n",
    "        self.layer2 = MultiHeadGATLayer(h_feats*num_heads, num_classes, h_feats*num_heads,__,1)\n",
    "\n",
    "    def forward(self, g, in_feat, e_feat):\n",
    "        #print(self.layer1(g, in_feat, e_feat)[1])\n",
    "        h, e = self.layer1(g, in_feat, e_feat)\n",
    "        #print(h.size())\n",
    "        h = F.elu(h)\n",
    "        e = F.elu(e)\n",
    "        h, e = self.layer2(g, h, e)\n",
    "        g.ndata[\"h\"] = h\n",
    "        return dgl.max_nodes(g, \"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4de6707d",
   "metadata": {
    "id": "4de6707d"
   },
   "outputs": [],
   "source": [
    "model = GAT1(\n",
    "            in_feats = 74,\n",
    "            h_feats = 60,\n",
    "            e_feats = 12,\n",
    "            num_classes = 12,\n",
    "            num_heads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "204e9b6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "204e9b6a",
    "outputId": "c7c35517-9360-49c4-cc04-c670d93b1828",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT1(\n",
      "  (layer1): MultiHeadGATLayer(\n",
      "    (heads): ModuleList(\n",
      "      (0-1): 2 x GATLayer1(\n",
      "        (fc): Linear(in_features=134, out_features=60, bias=False)\n",
      "        (fc1): Linear(in_features=12, out_features=60, bias=False)\n",
      "        (fc2): Linear(in_features=74, out_features=60, bias=False)\n",
      "        (attn_fc): Linear(in_features=120, out_features=1, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): MultiHeadGATLayer(\n",
      "    (heads): ModuleList(\n",
      "      (0): GATLayer1(\n",
      "        (fc): Linear(in_features=132, out_features=12, bias=False)\n",
      "        (fc1): Linear(in_features=120, out_features=12, bias=False)\n",
      "        (fc2): Linear(in_features=120, out_features=12, bias=False)\n",
      "        (attn_fc): Linear(in_features=24, out_features=1, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbc64f81",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "referenced_widgets": [
      "da0f1d47f1394bf89c5b8efe85091040",
      "6577469566af49caa91a9fe74a9a60eb",
      "7acbc2cd92784c07b6ba0258aed38adf",
      "6a7b9745a71f4d83952109db7dd09a79",
      "41ed424aa5bb404f890fb2c042fea51e",
      "1e453948442b46039de6eae2d6d6bee0",
      "38304f9d042d48f2a1f4453f2e8e8d39",
      "33337d9c0d4d47c9849c2c88121117a5",
      "5b6106c169414c42bdfcb1ccef229f84",
      "2910e5c24d5845498ad25e1a42e3a5fb",
      "10e8cbf7369740f3a92ca4d8655c56fb"
     ]
    },
    "id": "dbc64f81",
    "outputId": "8c672fd4-4615-44e6-9212-fe4c15315329",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhrub\\AppData\\Local\\Temp\\ipykernel_2372\\518592747.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss_criterion = BCEWithLogitsLoss(pos_weight=torch.tensor(dataset.task_pos_weights(train_ids)), reduction=\"none\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f86d00e8a84d40b3d0436e53e74cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Loss 4.7596 | Train Acc. 0.7125 | Validation Acc. 0.6914 \n",
      "Epoch 00001 | Loss 4.6077 | Train Acc. 0.7237 | Validation Acc. 0.6965 \n",
      "epoch 2/10, training roc-auc 0.6176\n"
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "run_a_train_epoch(train_loader, val_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d202f41d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d202f41d",
    "outputId": "66e9214a-7f99-464c-910e-febabab2ea91",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score 0.6853\n"
     ]
    }
   ],
   "source": [
    "test_score = run_an_eval_epoch(model, test_loader)\n",
    "print(\"Test score {:.4f}\".format(test_score))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "10e8cbf7369740f3a92ca4d8655c56fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e453948442b46039de6eae2d6d6bee0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2910e5c24d5845498ad25e1a42e3a5fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33337d9c0d4d47c9849c2c88121117a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38304f9d042d48f2a1f4453f2e8e8d39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41ed424aa5bb404f890fb2c042fea51e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b6106c169414c42bdfcb1ccef229f84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6577469566af49caa91a9fe74a9a60eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e453948442b46039de6eae2d6d6bee0",
      "placeholder": "​",
      "style": "IPY_MODEL_38304f9d042d48f2a1f4453f2e8e8d39",
      "value": "100%"
     }
    },
    "6a7b9745a71f4d83952109db7dd09a79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2910e5c24d5845498ad25e1a42e3a5fb",
      "placeholder": "​",
      "style": "IPY_MODEL_10e8cbf7369740f3a92ca4d8655c56fb",
      "value": " 2/2 [19:29&lt;00:00, 583.53s/it]"
     }
    },
    "7acbc2cd92784c07b6ba0258aed38adf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33337d9c0d4d47c9849c2c88121117a5",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5b6106c169414c42bdfcb1ccef229f84",
      "value": 2
     }
    },
    "da0f1d47f1394bf89c5b8efe85091040": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6577469566af49caa91a9fe74a9a60eb",
       "IPY_MODEL_7acbc2cd92784c07b6ba0258aed38adf",
       "IPY_MODEL_6a7b9745a71f4d83952109db7dd09a79"
      ],
      "layout": "IPY_MODEL_41ed424aa5bb404f890fb2c042fea51e"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
